Vamos direto.

Pelo enunciado e pelo código que você já tem, o trabalho está mais ou menos assim:

* Estrutura k-diagonal (`matdiag_t`) já implementada → atende ao requisito de **não guardar diagonais nulas**.
* PCG unificado (`cg_solve` + `pcg_*`) já pronto, com Jacobi/GS/SSOR.
* Função de resíduo otimizada (`residuo_l2_v2`) e `matvet_diagonais` já pensadas para v2.
* Makefile básico sem LIKWID ainda “plugado”.

Então os próximos passos são:

---

## 1. Fechar a V2 funcional (sem segfault e com resposta correta)

1. **Rodar testes pequenos e corrigir bugs:**

   * Rodar com `N` pequeno (32, 64, 128), `k=7`, `w=0` (Jacobi), `maxit` pequeno.
   * Verificar:

     * Não pode dar segfault / `munmap_chunk` / overflow.
     * A norma de resíduo final é pequena e faz sentido.
   * Se possível, comparar com:

     * Uma implementação densa antiga (v1) ou
     * Uma solução conhecida (por exemplo, resolver um sistema com solução conhecida e gerar `b = A x*`).

   **Objetivo desta fase:** deixar a V2 numericamente correta e estável. Qualquer crash agora vira nota 0, então esse é o primeiro gargalo a eliminar.

2. **Conferir geração SPD com a nova estrutura:**

   * Checar se `genSimetricaPositiva_diag`:

     * Usa **somente** `matdiag_t`, sem criar matriz densa NxN.
     * Não faz duplo `free` de `ASP`/`bsp`.
   * Validar que, após a transformação para SPD, o PCG converge consistentemente (resíduo decresce).

3. **Garantir critério de parada correto:**

   * O enunciado do T2 diz: **parar somente por número de iterações (= 25)** nos testes de desempenho.
   * Para a versão “acadêmica” (fora da fase de medição), você pode manter `||Δx||∞ < ε`.
   * Para os testes com LIKWID:

     * Adotar **critério exclusivo por `maxit`** (25) para padronizar as medidas.
     * Isto significa: no código, ter uma forma simples de escolher:

       * “modo testes” → para T2: parar só por iteração.
       * “modo solver normal” → usa o critério numérico.

---

## 2. Isolar e definir claramente op1 e op2 no código

Você precisa deixar explícito no código o que é op1 e o que é op2, porque o relatório e os gráficos giram em torno disso.

1. **op1 – iteração do PCG com Jacobi:**

   * Conceito: tudo que acontece **dentro do loop principal** do `cg_solve` quando:

     * `M = PCG_PRECOND_JACOBI` (ou `w = 0` na entrada).
   * Isso inclui:

     * Aplicação do pré-condicionador Jacobi: `y = D⁻¹ r`.
     * `v` (direção conjugada) sendo atualizado.
     * `z = A v` (matvec k-diagonal).
     * Atualização de `x` e `r`.
   * Opção boa: documentar com um comentário grande em cima do loop:

     ```c
     /* op1: uma iteração do método de Gradientes Conjugados
      * com pré-condicionador de Jacobi (M = D⁻¹).
      * É essa região que será medida com LIKWID como op1.
      */
     ```

2. **op2 – cálculo do resíduo R = b − A x:**

   * Você já tem algo como `residuo_l2_v2(A, b, x)` e dentro faz:

     * `Ax = A x` com `matvet_diagonais`.
     * `r = b − Ax` + acumulação da norma L2.
   * Essa função é seu **núcleo de op2**. Está bem isolada: ótimo para LIKWID e para discussão de otimização.

---

## 3. Integrar LIKWID (marcadores op1 e op2)

Agora entra a parte “de laboratório”.

1. **Incluir LIKWID condicionalmente:**

   No topo de `cgSolver.c`:

   ```c
   #ifdef LIKWID_PERFMON
   #include <likwid.h>
   #endif
   ```

   E no `main`:

   ```c
   int main(void) {
   #ifdef LIKWID_PERFMON
       LIKWID_MARKER_INIT;
   #endif

       /* ... resto do main ... */

   #ifdef LIKWID_PERFMON
       LIKWID_MARKER_CLOSE;
   #endif
       return 0;
   }
   ```

2. **Marcar op1 dentro do `cg_solve`:**

   Perto do loop principal:

   ```c
   #ifdef LIKWID_PERFMON
       LIKWID_MARKER_START("op1");
   #endif

   for (it = 0; it < maxit; ++it) {
       /* tudo da iteração CG/PCG aqui */
   }

   #ifdef LIKWID_PERFMON
       LIKWID_MARKER_STOP("op1");
   #endif
   ```

   * Isso acumula todos os contadores de op1 ao longo das 25 iterações.
   * O tempo médio por iteração você calcula com `timestamp()` como já está fazendo.

3. **Marcar op2 no `main` (mais limpo):**

   Em `cgSolver.c`, onde você já calcula o resíduo final:

   ```c
   rtime_t t_res = 0.0;
   real_t res_norm = 0.0;

   {
       rtime_t t0 = timestamp();
   #ifdef LIKWID_PERFMON
       LIKWID_MARKER_START("op2");
   #endif
       res_norm = residuo_l2_v2(&ASP, bsp, x);
   #ifdef LIKWID_PERFMON
       LIKWID_MARKER_STOP("op2");
   #endif
       t_res = timestamp() - t0;
   }
   ```

   * Assim você separa bem: tempo e contadores de op1 vs op2.

4. **Ajustar o Makefile para LIKWID:**

   No `Makefile`:

   ```make
   ifdef USE_LIKWID
   CFLAGS += -DLIKWID_PERFMON
   LFLAGS += -llikwid
   endif
   ```

   E manter as flags pedidas no enunciado:

   ```make
   CFLAGS = -O3 -march=native -mavx -fopt-info-vec -Wall -Wextra
   ```

---

## 4. Estruturar v1 e v2 e automatizar os testes

1. **Separar versões:**

   * Criar diretórios:

     * `v1/` → código do Trabalho 1 (denso, Jacobi padrão).
     * `v2/` → este código otimizado com k-diagonal e vetores.
   * Cada um com seu próprio `Makefile` (mesma interface de entrada/saída, mesmo executável `cgSolver`).

2. **Script de testes (run_tests.sh):**

   * Parâmetros fixos (do enunciado):

     * `N ∈ {32, 64, 128, 256, 512, 1000, 2000, 4000, 8000, 9000, 10000, 20000}`
     * `k = 7`
     * `w = 0` (Jacobi)
     * `maxit = 25`
     * `eps` pode ser qualquer positivo (não usado na parada).

   * Script faz, para cada versão (v1 e v2):

     * `make clean && USE_LIKWID=1 make`
     * Para cada `GROUP` em: `MEM`, `L2CACHE`, `FLOPS_DP`, `FLOPS_AVX`:

       * Para cada `N`:

         * Executar:

           ```bash
           likwid-perfctr -C 0 -g "$GROUP" -m ./cgSolver <<EOF >> results/<versao>_<GROUP>.log
           $N 7 0 25 1e-6
           EOF
           ```

   * Salvar tudo em `results/v1/` e `results/v2/` com organização clara.

3. **Geração dos gráficos:**

   * Exportar para CSV (ou ler diretamente dos logs) com Python/R/gnuplot.
   * Gerar gráficos:

     * 1 gráfico para **tempo de op1** (N x tempo médio por iteração) [eixo N e eixo tempo em **log**].
     * 1 gráfico para **tempo de op2** (N x tempo).
     * 1 gráfico para **banda de memória** op1; outro para op2.
     * 1 gráfico para **L2 miss ratio** op1; outro para op2.
     * 1 gráfico para **MFLOP/s** op1; outro para op2.
   * Cada gráfico: duas curvas → v1 e v2.

---

## 5. Fazer as estimativas analíticas (para o relatório)

Aqui você usa o modelo teórico do código v2:

1. **Memória (N máximo com 8 GB, k=7):**

   * Contar **quantos vetores de tamanho N** você tem simultaneamente:

     * `A` + `ASP` (matrizes k-diagonais): ≈ `2 * k * N` doubles.
     * Vetores: `b`, `bsp`, `x`, `r`, `v`, `z`, `y`, `D`, `invD` etc.
   * Escrever uma fórmula aproximada do tipo:

     [
     \text{Mem}(N) \approx c \cdot N ;\text{bytes}
     ]

     com `c` em torno de algumas centenas de bytes.
   * Impor `Mem(N) ≤ 8 GiB` e resolver para `N_max`.

2. **Ganho de tempo por iteração (v1 vs v2):**

   * v1 (denso): matvec `Ax` custa ≈ `O(N^2)` operações.

   * v2 (k-diagonal, k=7): matvec custa ≈ `O(k N)`.

   * Ganho teórico aproximado:

     [
     \frac{T_{v1}}{T_{v2}} \sim \frac{N^2}{kN} \approx \frac{N}{k}.
     ]

   * Discutir que para `N` grandes o speedup esperado cresce aproximadamente linearmente com `N` até outros gargalos (cache, memória).

3. **Flops por iteração do PCG com Jacobi:**

   * Abrir o `cg_solve` e contar:

     * `matvet_diagonais`: ~ `2kN` flops (mult + soma).
     * Jacobi: `N` divisões (ou multiplicações por `invD`).
     * Atualizações vetoriais (`x += αv`, `r -= αz`, `v = y + βv`).
   * Montar uma expressão do tipo:

     [
     \text{FLOPs_iter}(N) \approx a \cdot N,
     ]

     com `a` sendo um inteiro (soma dos coeficientes das operações).
   * Esta expressão será comparada com os MFLOP/s medidos (FLOPS_DP/AVX).

---

## 6. Redigir o relatório final

Estrutura mínima bem objetiva:

1. **Introdução**

   * Relembrar o problema (resolver sistemas k-diagonais SPD com PCG).
   * Diferenciar v1 (denso) de v2 (k-diagonal + otimizações).

2. **Metodologia**

   * Descrever:

     * Estrutura de dados v1 vs v2.
     * Otimizações implementadas (unroll, troca de estrutura, remoção de diagonais nulas, pré-condicionamento, etc.).
     * Como op1 e op2 foram definidos e medidos.

3. **Estimativas Teóricas**

   * N máximo com 8 GB (k=7).
   * Ganho de tempo por iteração (função de N).
   * Flops por iteração (função de N).

4. **Resultados Experimentais**

   * Apresentar os gráficos (v1 x v2 para op1/ op2 em todos os grupos).
   * Comentar cada gráfico: como os resultados se alinham (ou não) às estimativas.

5. **Conclusões**

   * O que você considera mais relevante:

     * Importância da estrutura k-diagonal.
     * Impacto real de trabalhar com menos memória.
     * Comportamento dos caches, MFLOP/s, etc.
   * Se buscar o bônus: mostrar evidência de AVX (trechos do `-fopt-info-vec` e/ou inspeção com `objdump`/`likwid-perfctr`).

---

Se você quiser, no próximo passo posso:

* Corrigir especificamente os trechos problemáticos (por exemplo, o `matvet_diagonais` que está estourando buffer).
* Escrever o esqueleto completo do `run_tests.sh` alinhado com este plano.
* Ajudar a montar as contas de memória/Flops em detalhe para colocar direto no relatório.
